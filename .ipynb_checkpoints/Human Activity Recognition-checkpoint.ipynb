{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition\n",
    "\n",
    "---\n",
    "\n",
    "We will Classify the type of activity a person is performing based on measurements collected from a smartphone. The activities include:  \n",
    "\n",
    "- Walking\n",
    "- Walking_Upstairs\n",
    "- Walking_Downstairs\n",
    "- Sitting\n",
    "- Standing\n",
    "- Laying\n",
    "\n",
    "-----\n",
    "\n",
    "Using the dataset [_Human Activity Recognition Using Smartphones Data Set_](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones) from the UC Irvine Machine Learning Repositiory.  \n",
    "\n",
    "Dataset description (as provided in the original authors):\n",
    "\n",
    "```\n",
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. \n",
    "\n",
    "The sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. See 'features_info.txt' for more details. \n",
    "\n",
    "For each record it is provided:\n",
    "\n",
    "- Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.\n",
    "- Triaxial Angular velocity from the gyroscope. \n",
    "- A 561-feature vector with time and frequency domain variables. \n",
    "- Its activity label. \n",
    "- An identifier of the subject who carried out the experiment.\n",
    "```\n",
    "\n",
    "[Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = 'features.txt'\n",
    "TRAIN_DATA = 'X_train.txt'\n",
    "TRAIN_LABELS = 'y_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature names\n",
    "df_feats = pd.read_table(FEATURE_NAMES, sep='\\n', header=None)\n",
    "\n",
    "# training data\n",
    "df_train = pd.read_table(TRAIN_DATA, sep='\\s+', header=None)\n",
    "\n",
    "# training labels\n",
    "df_train_labels = pd.read_table(TRAIN_LABELS, sep='\\n', header=None, names=[\"label\"], squeeze = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploring\n",
    "\n",
    "We want to have an idea of potential problems with data. In order to have a good model one has to look for Null or impossible values, and correlated features. With these done we can see if any features will not be useful in models becuase of null values and see if any model assumptions are violated by correlated features (such as in linear / logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
       "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
       "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
       "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
       "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.983185 -0.923527 -0.934724  ... -0.074323 -0.298676 -0.710304 -0.112754   \n",
       "1 -0.974914 -0.957686 -0.943068  ...  0.158075 -0.595051 -0.861499  0.053477   \n",
       "2 -0.963668 -0.977469 -0.938692  ...  0.414503 -0.390748 -0.760104 -0.118559   \n",
       "3 -0.982750 -0.989302 -0.938692  ...  0.404573 -0.117290 -0.482845 -0.036788   \n",
       "4 -0.979672 -0.990441 -0.942469  ...  0.087753 -0.351471 -0.699205  0.123320   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627  \n",
       "1 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317  \n",
       "2  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118  \n",
       "3 -0.012892  0.640011 -0.485366 -0.848649  0.181935 -0.047663  \n",
       "4  0.122542  0.693578 -0.615971 -0.847865  0.185151 -0.043892  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 561)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 tBodyAcc-mean()-X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 tBodyAcc-mean()-Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 tBodyAcc-mean()-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 tBodyAcc-std()-X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 tBodyAcc-std()-Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "0  1 tBodyAcc-mean()-X\n",
       "1  2 tBodyAcc-mean()-Y\n",
       "2  3 tBodyAcc-mean()-Z\n",
       "3   4 tBodyAcc-std()-X\n",
       "4   5 tBodyAcc-std()-Y"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give the name of the features to the columns of our training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 tBodyAcc-mean()-X</th>\n",
       "      <th>2 tBodyAcc-mean()-Y</th>\n",
       "      <th>3 tBodyAcc-mean()-Z</th>\n",
       "      <th>4 tBodyAcc-std()-X</th>\n",
       "      <th>5 tBodyAcc-std()-Y</th>\n",
       "      <th>6 tBodyAcc-std()-Z</th>\n",
       "      <th>7 tBodyAcc-mad()-X</th>\n",
       "      <th>8 tBodyAcc-mad()-Y</th>\n",
       "      <th>9 tBodyAcc-mad()-Z</th>\n",
       "      <th>10 tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>552 fBodyBodyGyroJerkMag-meanFreq()</th>\n",
       "      <th>553 fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>554 fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>555 angle(tBodyAccMean,gravity)</th>\n",
       "      <th>556 angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>557 angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>558 angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>559 angle(X,gravityMean)</th>\n",
       "      <th>560 angle(Y,gravityMean)</th>\n",
       "      <th>561 angle(Z,gravityMean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0  1 tBodyAcc-mean()-X  2 tBodyAcc-mean()-Y  3 tBodyAcc-mean()-Z  \\\n",
       "0             0.288585            -0.020294            -0.132905   \n",
       "1             0.278419            -0.016411            -0.123520   \n",
       "2             0.279653            -0.019467            -0.113462   \n",
       "3             0.279174            -0.026201            -0.123283   \n",
       "4             0.276629            -0.016570            -0.115362   \n",
       "\n",
       "0  4 tBodyAcc-std()-X  5 tBodyAcc-std()-Y  6 tBodyAcc-std()-Z  \\\n",
       "0           -0.995279           -0.983111           -0.913526   \n",
       "1           -0.998245           -0.975300           -0.960322   \n",
       "2           -0.995380           -0.967187           -0.978944   \n",
       "3           -0.996091           -0.983403           -0.990675   \n",
       "4           -0.998139           -0.980817           -0.990482   \n",
       "\n",
       "0  7 tBodyAcc-mad()-X  8 tBodyAcc-mad()-Y  9 tBodyAcc-mad()-Z  \\\n",
       "0           -0.995112           -0.983185           -0.923527   \n",
       "1           -0.998807           -0.974914           -0.957686   \n",
       "2           -0.996520           -0.963668           -0.977469   \n",
       "3           -0.997099           -0.982750           -0.989302   \n",
       "4           -0.998321           -0.979672           -0.990441   \n",
       "\n",
       "0  10 tBodyAcc-max()-X  ...  552 fBodyBodyGyroJerkMag-meanFreq()  \\\n",
       "0            -0.934724  ...                            -0.074323   \n",
       "1            -0.943068  ...                             0.158075   \n",
       "2            -0.938692  ...                             0.414503   \n",
       "3            -0.938692  ...                             0.404573   \n",
       "4            -0.942469  ...                             0.087753   \n",
       "\n",
       "0  553 fBodyBodyGyroJerkMag-skewness()  554 fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "0                            -0.298676                            -0.710304   \n",
       "1                            -0.595051                            -0.861499   \n",
       "2                            -0.390748                            -0.760104   \n",
       "3                            -0.117290                            -0.482845   \n",
       "4                            -0.351471                            -0.699205   \n",
       "\n",
       "0  555 angle(tBodyAccMean,gravity)  556 angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                        -0.112754                                  0.030400   \n",
       "1                         0.053477                                 -0.007435   \n",
       "2                        -0.118559                                  0.177899   \n",
       "3                        -0.036788                                 -0.012892   \n",
       "4                         0.123320                                  0.122542   \n",
       "\n",
       "0  557 angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                             -0.464761   \n",
       "1                             -0.732626   \n",
       "2                              0.100699   \n",
       "3                              0.640011   \n",
       "4                              0.693578   \n",
       "\n",
       "0  558 angle(tBodyGyroJerkMean,gravityMean)  559 angle(X,gravityMean)  \\\n",
       "0                                 -0.018446                 -0.841247   \n",
       "1                                  0.703511                 -0.844788   \n",
       "2                                  0.808529                 -0.848933   \n",
       "3                                 -0.485366                 -0.848649   \n",
       "4                                 -0.615971                 -0.847865   \n",
       "\n",
       "0  560 angle(Y,gravityMean)  561 angle(Z,gravityMean)  \n",
       "0                  0.179941                 -0.058627  \n",
       "1                  0.180289                 -0.054317  \n",
       "2                  0.180637                 -0.049118  \n",
       "3                  0.181935                 -0.047663  \n",
       "4                  0.185151                 -0.043892  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns = df_feats.iloc[:,0]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and check if there is any null values in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation plot of the first 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_twenty = har_train.iloc[:, :20] # pull out first 20 feats\n",
    "corr = first_twenty.corr()  # compute correlation matrix\n",
    "mask = np.zeros_like(corr, dtype=np.bool)  # make mask\n",
    "mask[np.triu_indices_from(mask)] = True  # mask the upper triangle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 9))  # create a figure and a subplot\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)  # custom color map\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    center=0,\n",
    "    linewidth=0.5,\n",
    "    cbar_kws={'shrink': 0.5}\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7352"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n",
    "\n",
    "---\n",
    "\n",
    "Comparing statistics within each activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 562)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train_labels \n",
    "X = df_train\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1 tBodyAcc-mean()-X</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.276260</td>\n",
       "      <td>0.261930</td>\n",
       "      <td>0.288169</td>\n",
       "      <td>0.273449</td>\n",
       "      <td>0.279294</td>\n",
       "      <td>0.269191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.050353</td>\n",
       "      <td>0.078029</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.101541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.121465</td>\n",
       "      <td>-0.061041</td>\n",
       "      <td>-0.161088</td>\n",
       "      <td>-0.412659</td>\n",
       "      <td>0.111231</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.433256</td>\n",
       "      <td>0.480180</td>\n",
       "      <td>0.617597</td>\n",
       "      <td>0.559135</td>\n",
       "      <td>0.631510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.274582</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>0.284955</td>\n",
       "      <td>0.277306</td>\n",
       "      <td>0.277507</td>\n",
       "      <td>0.276946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2 tBodyAcc-mean()-Y</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.017768</td>\n",
       "      <td>-0.026647</td>\n",
       "      <td>-0.016370</td>\n",
       "      <td>-0.012143</td>\n",
       "      <td>-0.016123</td>\n",
       "      <td>-0.018345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.027057</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.017846</td>\n",
       "      <td>0.073512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.127407</td>\n",
       "      <td>-0.183885</td>\n",
       "      <td>-0.094826</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>-0.116007</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.071488</td>\n",
       "      <td>0.100904</td>\n",
       "      <td>0.099755</td>\n",
       "      <td>0.324130</td>\n",
       "      <td>0.212768</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>-0.017867</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>-0.016457</td>\n",
       "      <td>-0.017097</td>\n",
       "      <td>-0.017364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">3 tBodyAcc-mean()-Z</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.108884</td>\n",
       "      <td>-0.120424</td>\n",
       "      <td>-0.105860</td>\n",
       "      <td>-0.106581</td>\n",
       "      <td>-0.107330</td>\n",
       "      <td>-0.107169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.060204</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>0.045323</td>\n",
       "      <td>0.035680</td>\n",
       "      <td>0.089743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.285675</td>\n",
       "      <td>-0.403290</td>\n",
       "      <td>-0.289816</td>\n",
       "      <td>-0.560934</td>\n",
       "      <td>-0.509645</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.091229</td>\n",
       "      <td>0.280939</td>\n",
       "      <td>0.267377</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>-0.110424</td>\n",
       "      <td>-0.113635</td>\n",
       "      <td>-0.109039</td>\n",
       "      <td>-0.108125</td>\n",
       "      <td>-0.108771</td>\n",
       "      <td>-0.108104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4 tBodyAcc-std()-X</th>\n",
       "      <th>count</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>1286.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.312641</td>\n",
       "      <td>-0.221072</td>\n",
       "      <td>0.139847</td>\n",
       "      <td>-0.983450</td>\n",
       "      <td>-0.985346</td>\n",
       "      <td>-0.959475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label                                 1            2           3            4  \\\n",
       "1 tBodyAcc-mean()-X count   1226.000000  1073.000000  986.000000  1286.000000   \n",
       "                    mean       0.276260     0.261930    0.288169     0.273449   \n",
       "                    std        0.050353     0.078029    0.095101     0.041998   \n",
       "                    min        0.121465    -0.061041   -0.161088    -0.412659   \n",
       "                    max        0.433256     0.480180    0.617597     0.559135   \n",
       "                    median     0.274582     0.266666    0.284955     0.277306   \n",
       "2 tBodyAcc-mean()-Y count   1226.000000  1073.000000  986.000000  1286.000000   \n",
       "                    mean      -0.017768    -0.026647   -0.016370    -0.012143   \n",
       "                    std        0.020880     0.037038    0.027057     0.032421   \n",
       "                    min       -0.127407    -0.183885   -0.094826    -0.121073   \n",
       "                    max        0.071488     0.100904    0.099755     0.324130   \n",
       "                    median    -0.017867    -0.023000   -0.017714    -0.016457   \n",
       "3 tBodyAcc-mean()-Z count   1226.000000  1073.000000  986.000000  1286.000000   \n",
       "                    mean      -0.108884    -0.120424   -0.105860    -0.106581   \n",
       "                    std        0.032436     0.060204    0.050656     0.045323   \n",
       "                    min       -0.285675    -0.403290   -0.289816    -0.560934   \n",
       "                    max        0.006195     0.142537    0.091229     0.280939   \n",
       "                    median    -0.110424    -0.113635   -0.109039    -0.108125   \n",
       "4 tBodyAcc-std()-X  count   1226.000000  1073.000000  986.000000  1286.000000   \n",
       "                    mean      -0.312641    -0.221072    0.139847    -0.983450   \n",
       "\n",
       "label                                 5            6  \n",
       "1 tBodyAcc-mean()-X count   1374.000000  1407.000000  \n",
       "                    mean       0.279294     0.269191  \n",
       "                    std        0.020097     0.101541  \n",
       "                    min        0.111231    -1.000000  \n",
       "                    max        0.631510     1.000000  \n",
       "                    median     0.277507     0.276946  \n",
       "2 tBodyAcc-mean()-Y count   1374.000000  1407.000000  \n",
       "                    mean      -0.016123    -0.018345  \n",
       "                    std        0.017846     0.073512  \n",
       "                    min       -0.116007    -1.000000  \n",
       "                    max        0.212768     1.000000  \n",
       "                    median    -0.017097    -0.017364  \n",
       "3 tBodyAcc-mean()-Z count   1374.000000  1407.000000  \n",
       "                    mean      -0.107330    -0.107169  \n",
       "                    std        0.035680     0.089743  \n",
       "                    min       -0.509645    -1.000000  \n",
       "                    max        0.267377     1.000000  \n",
       "                    median    -0.108771    -0.108104  \n",
       "4 tBodyAcc-std()-X  count   1374.000000  1407.000000  \n",
       "                    mean      -0.985346    -0.959475  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by the 'label' and show descriptive stats\n",
    "data.groupby('label').agg(['count', 'mean','std','min','max','median']).T.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Data\n",
    "\n",
    "With a feel for the data, now we will aside a \"test\" data-set that will allow us to evaluate out models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handmade KNN\n",
    "\n",
    "We will code from scratch the K-Nearest Neighbors algorithm with following the idea:\n",
    "given a value (with our movement-data, this \"value\" is better thought of as a vector of values) to be classified, KNN calculates the distance between that value and all other values in the training data-set. Then, the \"`k`\" nearest neighbors are polled as to their \"label\", and the given value is predicted to be of that majority value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_distances(test_point, data_set):\n",
    "    \n",
    "    # Take difference\n",
    "    diff = test_point - data_set\n",
    "    \n",
    "    # Calculate distance\n",
    "    dists = np.apply_along_axis(np.linalg.norm, 1, diff )\n",
    "    \n",
    "    # Sort distances values\n",
    "    dists = np.sort(dists)\n",
    "    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_of_smallest(numeric, labels, n):\n",
    "    \n",
    "    # Create a df of the two arrays (to simplify sorting)\n",
    "    con = np.concatenate((numeric.reshape(-1,1), labels.reshape(-1,1)), axis = 1)\n",
    "    df = pd.DataFrame(con, columns = [\"num\",\"lab\"])\n",
    "    \n",
    "    # Sort\n",
    "    df = df.sort_values(by = 'num')\n",
    "    \n",
    "    # Return the top \"n\" values (labels associated to points with smallest distance to input)\n",
    "    return df['lab'].head(n).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will find the majority vote label given an arbitrary set of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_voting(labels):\n",
    "    \n",
    "    # Recast labels as list\n",
    "    labels = list(labels)\n",
    "    \n",
    "    # Count the appereance of each label in the input. Returns a dictionary\n",
    "    c = Counter(labels).most_common()\n",
    "    \n",
    "    # If the list of labels has only one label\n",
    "    if len(c) == 1:\n",
    "        return c[0][0]\n",
    "    \n",
    "    # If there is a label with majority vote. Returns that label\n",
    "    if c[0][1] > c[1][1]:\n",
    "        return c[0][0]\n",
    "    \n",
    "    # For a tie. Return the one that appears first at the list\n",
    "    else:\n",
    "        top_votes = c[0][1]\n",
    "        #print(top_votes)\n",
    "        poss = []\n",
    "        for t in c:\n",
    "            if t[1] == top_votes:\n",
    "                poss.append(t[0])\n",
    "        idx = dict()\n",
    "        # print(poss)\n",
    "        for p in poss:\n",
    "            idx[labels.index(p)] = p\n",
    "        #print(idx)\n",
    "        return labels[sorted(idx.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible function for the majority vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt(labels):\n",
    "    \n",
    "    # Empty Dictionary\n",
    "    count = {}\n",
    "    \n",
    "    # Length of labels\n",
    "    total = len(labels)\n",
    "    \n",
    "    # Go through labels, add entry to dictionary for each with:\n",
    "    # count and first occurrence\n",
    "    for i, l in enumerate(labels):\n",
    "        if l in count:\n",
    "            count[l]['count'] +=1\n",
    "        else:\n",
    "            count[l] = {'count':1, 'first':total -i}\n",
    "            \n",
    "    # Create DataFrame from dict, sort, and return top result\n",
    "    df = pd.DataFrame.from_dict(count).T\n",
    "    df = df.sort_values(by = ['count','first'], ascending = False)\n",
    "    \n",
    "    # Return the label of the first value at the dict\n",
    "    # (the first value is the one with majority vote)\n",
    "    return df.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functions above which are encharged of calculating the distances from the input to other points, sort them and get the majority vote label we can code finally the function which is going to join all of this and predict the label for a point, given the training data and a specified number n of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_KNN( point, X_train, y_train, n):\n",
    "  \n",
    "    # Helper Function for vote counting\n",
    "    def countVotes(l):\n",
    "        \n",
    "        c = Counter(l).most_common()\n",
    "        \n",
    "        # List of labels of a single element\n",
    "        if len(c) == 1:\n",
    "            return c[0][0]\n",
    "        \n",
    "        # Case of majority vote\n",
    "        if c[0][1] > c[1][1]:\n",
    "            return c[0][0]\n",
    "        \n",
    "        # Case of a tie. Returns the first that appears in the list \n",
    "        else:\n",
    "            top_votes = c[0][1]\n",
    "            #print(top_votes)\n",
    "            poss = []\n",
    "            for t in c:\n",
    "                if t[1] == top_votes:\n",
    "                    poss.append(t[0])\n",
    "            idx = dict()\n",
    "            # print(poss)\n",
    "            for p in poss:\n",
    "                idx[l.index(p)] = p\n",
    "            #print(idx)\n",
    "            return l[sorted(idx.keys())[0]]\n",
    "        \n",
    "    # Take difference\n",
    "    diff = point - X_train\n",
    "    \n",
    "    # Find distance\n",
    "    dists = np.apply_along_axis(np.linalg.norm, 1, diff )\n",
    "    \n",
    "    # Create df of distances, re-index to original data\n",
    "    df = pd.DataFrame(dists)\n",
    "    df.index = X_train.index\n",
    "    \n",
    "    # Add labels, column names.\n",
    "    df = pd.concat([df, y_train], axis = 1)\n",
    "    df.columns = [\"dist\",\"label\"]\n",
    "    \n",
    "    # Take top votes, and count\n",
    "    votes = list(df.sort_values(\"dist\").head(n)['label'])\n",
    "    \n",
    "    return countVotes(votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying the Handmade Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new train-test partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K: Number of neighbors \n",
    "N: Number of predictions to be made from the test set\n",
    "G: Size of groups to be classied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_KNN_predictions(X_train, X_test, y_train, K, N, G):\n",
    "    \n",
    "    # Number of predictions to be made\n",
    "    print(\"Total 'test' observations:\", len(X_test))\n",
    "    \n",
    "    # Number of neighbors\n",
    "    print(\"Number of neighbors:\", K)\n",
    "    \n",
    "    # Number of predictions to be made\n",
    "    print(\"Number of predictions to be mde from the test set:\", N)\n",
    "    \n",
    "    # Frequently the number of predictions is large\n",
    "    # to avoid the prediction taking too long\n",
    "    # classify by groups \n",
    "    print(\"Classifying every point in X_test would take too long - classify by groups of\", G)\n",
    "    \n",
    "    # Create list of predictions\n",
    "    custom_preds = []\n",
    "    \n",
    "    # Process (number) of predictions\n",
    "    print(\"Number of predictions done:\")\n",
    "    \n",
    "    # Predict each point\n",
    "    for i, idx in enumerate(X_test.index[:N+1]):\n",
    "        if i % G == 0: print(i)\n",
    "        pred = custom_KNN(X_test.loc[idx,:], X_train, y_train, K)\n",
    "        custom_preds.append(pred)\n",
    "\n",
    "    # Predictions\n",
    "    print(\"\\nHome-Built predictions\")\n",
    "    \n",
    "    # Return all the predictions\n",
    "    return(custom_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 'test' observations: 2206\n",
      "Number of neighbors: 5\n",
      "Number of predictions to be mde from the test set: 1000\n",
      "Classifying every point in X_test would take too long - classify by groups of 200\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_KNN_predictions(X_train, X_test, y_train, 5, 1000, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn KNN\n",
    "\n",
    "Using the `sklearn` implementation [KNeighborsClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) \n",
    "\n",
    "It will run much faster than our home-built version.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def sklearn_KNN(X_train, X_test, y_train, K, N):\n",
    "\n",
    "    # Instantiate classifier\n",
    "    # The default distance is Euclidean\n",
    "    knn = KNeighborsClassifier(n_neighbors = K)\n",
    "\n",
    "    # Fit model with training data\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Create predictions for first 200 test observations\n",
    "    skpreds = knn.predict(X_test[:N])\n",
    "\n",
    "    print(\"sklearn prediction performance\")\n",
    "    return(classification_report(y_test[:N], skpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn prediction performance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 4, 3, 1, 4, 4, 5, 6, 3, 1, 3, 2, 1, 3, 4, 5, 6, 1, 1, 1, 2,\n",
       "       3, 6, 4, 2, 6, 2, 3, 5, 5, 5, 1, 3, 2, 4, 2, 1, 5, 6, 1, 5, 4, 5,\n",
       "       6, 4, 5, 2, 2, 1, 3, 5, 2, 6, 2, 6, 6, 1, 1, 6, 5, 4, 5, 5, 6, 5,\n",
       "       4, 5, 4, 2, 2, 4, 5, 4, 5, 1, 4, 2, 1, 5, 2, 4, 3, 6, 2, 3, 5, 1,\n",
       "       6, 2, 6, 6, 4, 3, 1, 1, 1, 5, 1, 4, 4, 5, 2, 2, 1, 6, 1, 2, 3, 6,\n",
       "       4, 1, 1, 6, 2, 2, 1, 6, 6, 6, 2, 3, 1, 1, 3, 4, 6, 5, 2, 6, 6, 4,\n",
       "       6, 6, 3, 6, 1, 1, 2, 4, 1, 1, 1, 4, 1, 2, 6, 1, 5, 2, 3, 2, 6, 4,\n",
       "       6, 1, 3, 4, 1, 3, 5, 5, 2, 3, 5, 1, 4, 1, 2, 2, 6, 1, 2, 1, 5, 1,\n",
       "       6, 5, 1, 6, 6, 4, 6, 6, 5, 2, 2, 5, 2, 3, 3, 5, 4, 5, 6, 1, 6, 1,\n",
       "       5, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_KNN(X_train, X_test, y_train, 5, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Home-Built with Sklearn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparing_predictions(y_test, custom_preds, N):\n",
    "\n",
    "    print(\"\\nHome-Built prediction performance\")\n",
    "    print(classification_report(y_test[:N+1], custom_preds))\n",
    "\n",
    "\n",
    "    # Compare predictions: \"differences\" should == 0!\n",
    "\n",
    "    differences = 0\n",
    "    for cust, sk in zip(custom_preds, skpreds):\n",
    "        if cust != sk:\n",
    "            differences +=1\n",
    "    return(\"Total Differences:\", differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Home-Built prediction performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        44\n",
      "           2       0.97      1.00      0.99        33\n",
      "           3       1.00      0.95      0.98        22\n",
      "           4       0.82      0.92      0.87        25\n",
      "           5       0.94      0.86      0.90        36\n",
      "           6       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           0.96       201\n",
      "   macro avg       0.96      0.96      0.95       201\n",
      "weighted avg       0.96      0.96      0.96       201\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Total Differences:', 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparing_predictions(y_test, custom_preds, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
